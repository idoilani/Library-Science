{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StackOverFlow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Gal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general imports\n",
    "# please make sure you have gensim (if you don't use: pip install gensim)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "# sys.path.append(\"C:/Users/Gal/PycharmProjects/GroundInstances/\")\n",
    "# from create_user_profile import *\n",
    "# from clean_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification imports \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project definition\n",
    "project_dir = '/Users/Gal/Documents/Repositories/Workshop-in-Data-Science/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the final dataframe with all the fetures might take several hours,\n",
    "# Here we use the basic dataframes we got from Kaggle to show you how we extracted the relevant features\n",
    "from clean_data import clean_data\n",
    "\n",
    "clean_data(project_dir + '/data/Answers.csv', project_dir + '/data/Clean_Answers.csv')\n",
    "clean_data(project_dir + '/data/Questions.csv', project_dir + '/data/Clean_Questions.csv')\n",
    "clean_data(project_dir + '/data/Tags.csv', project_dir + '/data/Clean_Tags.csv')\n",
    "\n",
    "ans = pd.read_csv(project_dir + '/data/Clean_Answers.csv')\n",
    "qus = pd.read_csv( project_dir + '/data/Clean_Questions.csv')\n",
    "tags = pd.read_csv( project_dir + '/data/Clean_Tags.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  First Observation on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>Score</th>\n",
       "      <th>IsAcceptedAnswer</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79741</td>\n",
       "      <td>3259.0</td>\n",
       "      <td>2008-09-17T03:43:22Z</td>\n",
       "      <td>79709</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;p&gt;It's tough to say definitively without know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79768</td>\n",
       "      <td>6043.0</td>\n",
       "      <td>2008-09-17T03:48:29Z</td>\n",
       "      <td>79709</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;p&gt;use variables in the outer function instead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79779</td>\n",
       "      <td>8002.0</td>\n",
       "      <td>2008-09-17T03:49:36Z</td>\n",
       "      <td>79709</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;p&gt;Third approach: inner function returns a re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79827</td>\n",
       "      <td>14257.0</td>\n",
       "      <td>2008-09-17T03:58:26Z</td>\n",
       "      <td>79709</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;p&gt;I'm not sure I understand the question, but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79893</td>\n",
       "      <td>14928.0</td>\n",
       "      <td>2008-09-17T04:11:08Z</td>\n",
       "      <td>79709</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;p&gt;Remember your Knuth.  \"Premature optimizati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  OwnerUserId          CreationDate  ParentId  Score  \\\n",
       "0  79741       3259.0  2008-09-17T03:43:22Z     79709     -1   \n",
       "1  79768       6043.0  2008-09-17T03:48:29Z     79709      9   \n",
       "2  79779       8002.0  2008-09-17T03:49:36Z     79709      0   \n",
       "3  79827      14257.0  2008-09-17T03:58:26Z     79709      1   \n",
       "4  79893      14928.0  2008-09-17T04:11:08Z     79709      6   \n",
       "\n",
       "   IsAcceptedAnswer                                               Body  \n",
       "0             False  <p>It's tough to say definitively without know...  \n",
       "1             False  <p>use variables in the outer function instead...  \n",
       "2             False  <p>Third approach: inner function returns a re...  \n",
       "3             False  <p>I'm not sure I understand the question, but...  \n",
       "4             False  <p>Remember your Knuth.  \"Premature optimizati...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77434</td>\n",
       "      <td>14008.0</td>\n",
       "      <td>2008-09-16T21:40:29Z</td>\n",
       "      <td>171</td>\n",
       "      <td>How to access the last value in a vector?</td>\n",
       "      <td>&lt;p&gt;Suppose I have a vector that is nested in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95007</td>\n",
       "      <td>15842.0</td>\n",
       "      <td>2008-09-18T17:59:19Z</td>\n",
       "      <td>56</td>\n",
       "      <td>Explain the quantile() function in R</td>\n",
       "      <td>&lt;p&gt;I've been mystified by the R quantile funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255697</td>\n",
       "      <td>1941213.0</td>\n",
       "      <td>2008-11-01T15:48:30Z</td>\n",
       "      <td>4</td>\n",
       "      <td>Is there an R package for learning a Dirichlet...</td>\n",
       "      <td>&lt;p&gt;I'm looking for a an &lt;code&gt;R&lt;/code&gt; package...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>359438</td>\n",
       "      <td>2173.0</td>\n",
       "      <td>2008-12-11T14:02:06Z</td>\n",
       "      <td>4</td>\n",
       "      <td>Optimization packages for R</td>\n",
       "      <td>&lt;p&gt;Does anyone know of any optimization packag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>439526</td>\n",
       "      <td>37751.0</td>\n",
       "      <td>2009-01-13T15:58:48Z</td>\n",
       "      <td>23</td>\n",
       "      <td>Thinking in Vectors with R</td>\n",
       "      <td>&lt;p&gt;I know that R works most efficiently with v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  OwnerUserId          CreationDate  Score  \\\n",
       "0   77434      14008.0  2008-09-16T21:40:29Z    171   \n",
       "1   95007      15842.0  2008-09-18T17:59:19Z     56   \n",
       "2  255697    1941213.0  2008-11-01T15:48:30Z      4   \n",
       "3  359438       2173.0  2008-12-11T14:02:06Z      4   \n",
       "4  439526      37751.0  2009-01-13T15:58:48Z     23   \n",
       "\n",
       "                                               Title  \\\n",
       "0          How to access the last value in a vector?   \n",
       "1               Explain the quantile() function in R   \n",
       "2  Is there an R package for learning a Dirichlet...   \n",
       "3                        Optimization packages for R   \n",
       "4                         Thinking in Vectors with R   \n",
       "\n",
       "                                                Body  \n",
       "0  <p>Suppose I have a vector that is nested in a...  \n",
       "1  <p>I've been mystified by the R quantile funct...  \n",
       "2  <p>I'm looking for a an <code>R</code> package...  \n",
       "3  <p>Does anyone know of any optimization packag...  \n",
       "4  <p>I know that R works most efficiently with v...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qus.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77434</td>\n",
       "      <td>vector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79709</td>\n",
       "      <td>memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79709</td>\n",
       "      <td>function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79709</td>\n",
       "      <td>global-variables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79709</td>\n",
       "      <td>side-effects</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id               Tag\n",
       "0  77434            vector\n",
       "1  79709            memory\n",
       "2  79709          function\n",
       "3  79709  global-variables\n",
       "4  79709      side-effects"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning data and save it back to the same directory\n",
      "reading it back...\n",
      "Split to train and test and prepare user data_frame from train and add columns for the NLP features\n",
      "saving data frames\n",
      "applying gensim models on train and test data frames\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 223050 is out of bounds for axis 1 with size 223050",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-d059a2c9053c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Gal\\Documents\\Repositories\\Workshop-in-Data-Science\\main.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"applying gensim models on train and test data frames\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gensim_model_on_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda_qus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"clean_qus\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gensim_model_on_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda_ans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"clean_ans\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Gal\\Documents\\Repositories\\Workshop-in-Data-Science\\nlp_features.pyc\u001b[0m in \u001b[0;36mapply_gensim_model_on_df\u001b[1;34m(gensim_model, df, column, is_ans)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[0mbow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_document_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"topic_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Gal\\Anaconda2\\lib\\site-packages\\gensim\\models\\ldamodel.pyc\u001b[0m in \u001b[0;36mget_document_topics\u001b[1;34m(self, bow, minimum_probability, minimum_phi_value, per_word_topics)\u001b[0m\n\u001b[0;32m   1308\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1310\u001b[1;33m         \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollect_sstats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1311\u001b[0m         \u001b[0mtopic_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# normalize distribution\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Gal\\Anaconda2\\lib\\site-packages\\gensim\\models\\ldamodel.pyc\u001b[0m in \u001b[0;36minference\u001b[1;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[0;32m    660\u001b[0m             \u001b[0mElogthetad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mElogtheta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m             \u001b[0mexpElogthetad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpElogtheta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m             \u001b[0mexpElogbetad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpElogbeta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m             \u001b[1;31m# The optimal phi_{dwk} is proportional to expElogthetad_k * expElogbetad_w.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 223050 is out of bounds for axis 1 with size 223050"
     ]
    }
   ],
   "source": [
    "import main\n",
    "main.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nlp_features.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[new_col] = df[orig_col].apply(clean_column)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving data frames\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EXCUTE THIS - it's add a lot of feature - it's better using the prepared Datafram next cell\n",
    "from clean_data import split_to_train_test\n",
    "train_df, test_df = split_to_train_test(qus, ans, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(project_dir + 'data/clean_data/train_with_tag_clusters_and_user_scores.csv')\n",
    "test_df = pd.read_csv(project_dir + 'data/clean_data/test_with_tag_clusters_and_user_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating users list and graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is also might take a time ~ 2 hours\n",
    "from create_user_profile import *\n",
    "users = list_of_users(train_df)\n",
    "users.create_user_graph()\n",
    "users.set_node_properties()\n",
    "users.set_user_scores(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the objects\n",
    "user_df = users.generate_data_frame(project_dir + \"\\user_dataframe.csv\")\n",
    "users.save_obj(project_dir + \"\\user_list.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading objects\n",
    "user_df = pd.read_csv('C:\\Users\\Gal\\Documents\\Library-Science\\user_dataframe.csv')\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df[user_df['neg_questions'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User's graph analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = list_of_users.load_obj(project_dir  + 'user_list.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### devide to sub graphs and some details of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2425 157144 53956\n"
     ]
    }
   ],
   "source": [
    "print len(list(nx.weakly_connected_component_subgraphs(G.graph))), G.graph.number_of_edges(), G.graph.number_of_nodes()\n",
    "sub_graphs = list(nx.weakly_connected_component_subgraphs(G.graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Largest components - most of the users are connected in the same component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 5, 5, 5, 5, 6, 6, 8, 50018]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([len(x) for x in sub_graphs])[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification imports \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df loaded\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['diff_percentile_bucket' 'hirerchy'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-3dda806aaac4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# training - random forest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mrandom_forest_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mrandom_forest_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mall_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mresults_random_forest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_forest_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mall_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Gal\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2677\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2678\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2679\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2680\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2681\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Gal\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2721\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2722\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2723\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2724\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Gal\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1325\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[1;32m-> 1327\u001b[1;33m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['diff_percentile_bucket' 'hirerchy'] not in index\""
     ]
    }
   ],
   "source": [
    "# NN tests are in different module since we need tensorflow enviornment \n",
    "train_df = pd.read_csv(project_dir + '/data/train_df.csv')\n",
    "test_df = pd.read_csv(project_dir + '/data/test_df.csv')\n",
    "\n",
    "train_df.fillna(0, inplace=True)\n",
    "test_df.fillna(0, inplace=True)\n",
    "\n",
    "# define all features\n",
    "basic_features = ['Score_ans', 'Score_qus']\n",
    "nlp_features = ['topic_' + str(i) + \"_qus\" for i in range(10)] + ['topic_' + str(i) + \"_ans\" for i in range(10)]\n",
    "time_features = ['diff_percentile_bucket', 'hirerchy']\n",
    "tags_features = [\"cluster_\" + str(i) for i in range(50)] + [\"user_score_cluster_\" + str(i) for i in range(50)]\\\n",
    "                + [\"user_score_general\",\"total_score_user_question_by_clusters\", \"total_score_user_question_by_clusters_relative\"]\n",
    "users_features = ['neg_answers_user', 'neg_questions_user', 'number_of_answers_user', 'out_degree_user', 'question_total_score_user',\n",
    "                 'answer_total_score_user', 'closeness_centrality_user', 'in_degree_user']\n",
    "\n",
    "all_features = basic_features + users_features + time_features # + nlp_features # + tags_features\n",
    "target = 'IsAcceptedAnswer'\n",
    "\n",
    "# training - random forest\n",
    "random_forest_clf = RandomForestClassifier(n_estimators=300, max_depth=5, random_state=0)\n",
    "random_forest_clf.fit(train_df[all_features], train_df[target])\n",
    "results_random_forest = random_forest_clf.predict(test_df[all_features])\n",
    "\n",
    "correct_predictions = np.sum(results_random_forest == np.array(test_df[target]))\n",
    "\n",
    "print \"results of random forest:\"\n",
    "print (correct_predictions) / float(len(results_random_forest))\n",
    "\n",
    "# training - logistic regression\n",
    "# Iterated over parameters: pentalty {l1, l2}\n",
    "logisticRegr = LogisticRegression(max_iter=5000, class_weight='balanced', penalty='l2')\n",
    "logisticRegr.fit(train_df[all_features], train_df[target])\n",
    "correct_predictions = np.sum(logisticRegr.predict(test_df[all_features]) == test_df[target])\n",
    "\n",
    "print \"results of logistic regression:\"\n",
    "print correct_predictions / float(len(test_df[target]))\n",
    "\n",
    "\n",
    "# training - SVM \n",
    "# clf = svm.SVC()\n",
    "# clf.fit(train_df[all_features], train_df[target]) \n",
    "# correct_predictions = np.sum(clf.predict(test_df[all_features]) ==  test_df[target])\n",
    "\n",
    "# print \"results of SVM:\"\n",
    "# print correct_predictions / float(len(test_df[target]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49181"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test_df['IsAcceptedAnswer'] == results_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(ans[\"IsAcceptedAnswer\"]) / float(len(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "c = collections.Counter(tags[\"Id\"])\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ans score - IsAccepted graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "F = [x for x in ans[ans['IsAcceptedAnswer'] == False]['Score'] if x > -10 or x<50]\n",
    "T = [x for x in ans[ans['IsAcceptedAnswer'] == True]['Score'] if x > -10 or x<50]\n",
    "bins = np.linspace(-10, 20, 30)\n",
    "\n",
    "plt.hist(F, bins, alpha=0.5, label='Not accepted')\n",
    "plt.hist(T, bins, alpha=0.5, label='Accepted', weights=[len(T)/float(len(F))]*len(T))\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('# samples')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ans), len(qus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans[ans['IsAcceptedAnswer'] == False]['ParentId'].nunique(), len(ans[ans['IsAcceptedAnswer'] == False]['ParentId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'all', u'just', u'being', u'over', u'both', u'through', u'yourselves', u'its', u'before', u'o', u'hadn', u'herself', u'll', u'had', u'should', u'to', u'only', u'won', u'under', u'ours', u'has', u'do', u'them', u'his', u'very', u'they', u'not', u'during', u'now', u'him', u'nor', u'd', u'did', u'didn', u'this', u'she', u'each', u'further', u'where', u'few', u'because', u'doing', u'some', u'hasn', u'are', u'our', u'ourselves', u'out', u'what', u'for', u'while', u're', u'does', u'above', u'between', u'mustn', u't', u'be', u'we', u'who', u'were', u'here', u'shouldn', u'hers', u'by', u'on', u'about', u'couldn', u'of', u'against', u's', u'isn', u'or', u'own', u'into', u'yourself', u'down', u'mightn', u'wasn', u'your', u'from', u'her', u'their', u'aren', u'there', u'been', u'whom', u'too', u'wouldn', u'themselves', u'weren', u'was', u'until', u'more', u'himself', u'that', u'but', u'don', u'with', u'than', u'those', u'he', u'me', u'myself', u'ma', u'these', u'up', u'will', u'below', u'ain', u'can', u'theirs', u'my', u'and', u've', u'then', u'is', u'am', u'it', u'doesn', u'an', u'as', u'itself', u'at', u'have', u'in', u'any', u'if', u'again', u'no', u'when', u'same', u'how', u'other', u'which', u'you', u'shan', u'needn', u'haven', u'after', u'most', u'such', u'why', u'a', u'off', u'i', u'm', u'yours', u'so', u'y', u'the', u'having', u'once'])\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "print stopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gal\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building a model for questions\n",
      "building a model for answers\n"
     ]
    }
   ],
   "source": [
    "# this how to generate topics for questions and answers - also it might take a while... \n",
    "from nlp_features import *\n",
    "train_df = pd.read_csv(project_dir + '/data/clean_data/train_with_tag_clusters_and_user_scores.csv')\n",
    "q_docs = train_df['clean_qus']\n",
    "a_docs = train_df['clean_ans']\n",
    "\n",
    "q_docs = [x.split(\" \") for x in q_docs if type(x)!=float]\n",
    "a_docs = [x.split(\" \") for x in a_docs if type(x)!=float]\n",
    "\n",
    "q_dictionary = corpora.Dictionary(q_docs)\n",
    "q_doc_term_matrix = [q_dictionary.doc2bow(doc) for doc in q_docs]\n",
    "\n",
    "a_dictionary = corpora.Dictionary(a_docs)\n",
    "a_doc_term_matrix = [a_dictionary.doc2bow(doc) for doc in a_docs]\n",
    "\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "print \"building a model for questions\"\n",
    "q_ldamodel = Lda(q_doc_term_matrix, num_topics=10, id2word=q_dictionary, passes=50)\n",
    "q_ldamodel.save(\"my_lda_model_qus_10_topics\")\n",
    "\n",
    "print \"building a model for answers\"\n",
    "a_ldamodel = Lda(a_doc_term_matrix, num_topics=10, id2word=a_dictionary, passes=50)\n",
    "a_ldamodel.save(\"my_lda_model_ans_10_topics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### veryfining that topics make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, u'0.017*\"~\" + 0.014*\"number\" + 0.014*\"matrix\" + 0.014*\"data\" + 0.011*\"time\" + 0.011*\"values\" + 0.010*\"vector\" + 0.010*\"model\" + 0.010*\"value\" + 0.008*\"element\" + 0.008*\"length\" + 0.006*\"first\" + 0.005*\"test\" + 0.005*\"calculate\" + 0.005*\"two\" + 0.005*\"random\" + 0.005*\"mean\" + 0.005*\"returns\" + 0.005*\"function\" + 0.005*\"/\"')\n",
      "(1, u'0.103*\"1\" + 0.098*\"2\" + 0.072*\"3\" + 0.062*\"na\" + 0.053*\"4\" + 0.041*\"5\" + 0.033*\"b\" + 0.031*\"6\" + 0.021*\"7\" + 0.021*\"8\" + 0.020*\"c\" + 0.018*\"10\" + 0.016*\"9\" + 0.010*\"x\" + 0.010*\"$\" + 0.010*\"12\" + 0.009*\"11\" + 0.007*\"id\" + 0.007*\"13\" + 0.006*\"15\"')\n",
      "(2, u'0.042*\"image\" + 0.041*\"description\" + 0.035*\"*\" + 0.023*\"plot\" + 0.021*\"x\" + 0.014*\"color\" + 0.012*\"size\" + 0.012*\"fill\" + 0.011*\"labels\" + 0.010*\"add\" + 0.010*\"max\" + 0.010*\"/\" + 0.010*\"mean\" + 0.010*\"col\" + 0.009*\"label\" + 0.008*\"min\" + 0.008*\"p\" + 0.008*\"width\" + 0.007*\"points\" + 0.007*\"use\"')\n",
      "(3, u'0.019*\"function\" + 0.019*\"use\" + 0.012*\"like\" + 0.012*\"would\" + 0.011*\"want\" + 0.010*\"need\" + 0.010*\"code\" + 0.010*\"false\" + 0.010*\"using\" + 0.008*\"true\" + 0.008*\"one\" + 0.008*\"also\" + 0.007*\"could\" + 0.007*\"see\" + 0.007*\"r\" + 0.007*\"don\\'t\" + 0.006*\"way\" + 0.006*\"it\\'s\" + 0.006*\"get\" + 0.006*\"think\"')\n",
      "(4, u'0.008*\"33\" + 0.007*\"col1\" + 0.006*\"col2\" + 0.006*\"setosa\" + 0.004*\"perl\" + 0.004*\"class\" + 0.003*\"species\" + 0.003*\"markdown\" + 0.003*\"150\" + 0.003*\"[\" + 0.003*\"spark\" + 0.003*\"lty\" + 0.003*\"col3\" + 0.002*\"state\" + 0.002*\"elispot\" + 0.002*\"offset\" + 0.002*\"ordering\" + 0.002*\"76\" + 0.002*\"date\" + 0.002*\"docs\"')\n",
      "(5, u'0.341*\"0\" + 0.212*\"1\" + 0.009*\"100\" + 0.005*\"2\" + 0.005*\"00\" + 0.005*\"200\" + 0.004*\"2010\" + 0.004*\"110\" + 0.004*\"john\" + 0.004*\"101\" + 0.003*\"wt\" + 0.003*\"vs\" + 0.003*\"disp\" + 0.003*\"300\" + 0.002*\"hp\" + 0.002*\"rx4\" + 0.002*\"box1\" + 0.002*\"var2\" + 0.002*\"102\" + 0.002*\"var1\"')\n",
      "(6, u'0.043*\"data\" + 0.032*\"use\" + 0.025*\"column\" + 0.017*\"using\" + 0.015*\"create\" + 0.014*\"columns\" + 0.013*\"first\" + 0.013*\"get\" + 0.011*\"row\" + 0.011*\"want\" + 0.011*\"rows\" + 0.011*\"list\" + 0.011*\"values\" + 0.010*\"frame\" + 0.010*\"convert\" + 0.009*\"names\" + 0.009*\"need\" + 0.009*\"one\" + 0.009*\"new\" + 0.009*\"date\"')\n",
      "(7, u'0.063*\"[1]\" + 0.017*\"string\" + 0.013*\"match\" + 0.012*\"pattern\" + 0.011*\"collapse\" + 0.010*\"x1\" + 0.010*\"start\" + 0.009*\"end\" + 0.009*\"x2\" + 0.009*\"regex\" + 0.009*\"characters\" + 0.008*\"character\" + 0.008*\"matches\" + 0.007*\"2000\" + 0.007*\"followed\" + 0.007*\"return\" + 0.006*\"text\" + 0.006*\"use\" + 0.006*\"replace\" + 0.006*\"double\"')\n",
      "(8, u'0.029*\"r\" + 0.024*\"file\" + 0.017*\"package\" + 0.012*\"version\" + 0.010*\"using\" + 0.010*\"server\" + 0.009*\"code\" + 0.008*\"files\" + 0.007*\"install\" + 0.006*\"use\" + 0.006*\"run\" + 0.006*\"read\" + 0.006*\"packages\" + 0.005*\"following\" + 0.005*\"command\" + 0.005*\"load\" + 0.005*\"text\" + 0.005*\"working\" + 0.005*\"path\" + 0.005*\"need\"')\n",
      "(9, u'0.183*\"#\" + 0.020*\"else\" + 0.017*\"##\" + 0.013*\"n\" + 0.010*\"user\" + 0.009*\"sep\" + 0.008*\"ncol\" + 0.007*\"yes\" + 0.007*\"var\" + 0.007*\"title\" + 0.007*\"pieces\" + 0.006*\"x\" + 0.006*\"system\" + 0.006*\"nrow\" + 0.005*\"elapsed\" + 0.005*\"dt\" + 0.004*\"res\" + 0.004*\"2012\" + 0.004*\"df\" + 0.004*\"55\"')\n"
     ]
    }
   ],
   "source": [
    "for x in a_ldamodel.print_topics(num_topics=10, num_words=20):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### verifying that scores to each doc makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 0.70084924), (8, 0.28314927)]\n",
      "[(0, 0.39112002), (1, 0.025), (2, 0.02500137), (3, 0.40887052), (4, 0.025), (5, 0.025), (6, 0.025002552), (7, 0.025), (8, 0.025005588), (9, 0.025)]\n",
      "[(0, 0.12699741), (2, 0.22358847), (3, 0.49486497), (7, 0.10000015)]\n",
      "[(0, 0.21933755), (3, 0.38200584), (8, 0.3448088)]\n",
      "[(1, 0.40886503), (7, 0.4306464), (8, 0.12714858)]\n",
      "[(0, 0.17579961), (1, 0.49311706), (2, 0.045494415), (3, 0.25570112), (5, 0.020795628)]\n",
      "[(0, 0.18219188), (1, 0.014285768), (2, 0.014286166), (3, 0.7035199), (4, 0.014285714), (5, 0.014285714), (6, 0.014286555), (7, 0.014285775), (8, 0.014286356), (9, 0.014286191)]\n",
      "[(0, 0.07689339), (3, 0.54721534), (4, 0.061111346), (8, 0.28143942)]\n",
      "[(3, 0.6876724), (6, 0.2395936)]\n",
      "[(3, 0.8194172), (8, 0.1570521)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    bow = a_dictionary.doc2bow(a_docs[i])\n",
    "    t = a_ldamodel.get_document_topics(bow)\n",
    "    print t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some properties of NLP features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "u\"None of [['topic_0_qus_Ans', 'topic_1_qus_Ans', 'topic_2_qus_Ans', 'topic_3_qus_Ans', 'topic_4_qus_Ans', 'topic_5_qus_Ans', 'topic_6_qus_Ans', 'topic_7_qus_Ans', 'topic_8_qus_Ans', 'topic_9_qus_Ans']] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-193a6c4a7816>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mreject_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain_df\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'IsAcceptedAnswer'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mD_accept\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_correlations_in_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccept_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mD_reject\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_correlations_in_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreject_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Gal\\Documents\\Repositories\\Workshop-in-Data-Science\\nlp_features.pyc\u001b[0m in \u001b[0;36mfind_correlations_in_topics\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mans_topics\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[0mans_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mans_topics\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[0mqus_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mqus_topics\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0mans_index\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mqus_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqus_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Gal\\Anaconda2\\lib\\site-packages\\pandas\\core\\series.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 809\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Gal\\Anaconda2\\lib\\site-packages\\pandas\\core\\series.pyc\u001b[0m in \u001b[0;36m_get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    848\u001b[0m                     \u001b[1;31m# handle the dup indexing case (GH 4246)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 850\u001b[1;33m                         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Gal\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1477\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1478\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1480\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Gal\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.pyc\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1899\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot index with multidimensional key'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1900\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1901\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1903\u001b[0m             \u001b[1;31m# nested tuple slicing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Gal\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.pyc\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1141\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m                 \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Gal\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.pyc\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis)\u001b[0m\n\u001b[0;32m   1204\u001b[0m                 raise KeyError(\n\u001b[0;32m   1205\u001b[0m                     u\"None of [{key}] are in the [{axis}]\".format(\n\u001b[1;32m-> 1206\u001b[1;33m                         key=key, axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[0;32m   1207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m             \u001b[1;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: u\"None of [['topic_0_qus_Ans', 'topic_1_qus_Ans', 'topic_2_qus_Ans', 'topic_3_qus_Ans', 'topic_4_qus_Ans', 'topic_5_qus_Ans', 'topic_6_qus_Ans', 'topic_7_qus_Ans', 'topic_8_qus_Ans', 'topic_9_qus_Ans']] are in the [index]\""
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(project_dir + 'data/clean_data/train_with_tag_clusters_and_user_scores.csv')\n",
    "accept_df = train_df [train_df ['IsAcceptedAnswer'] == 1]\n",
    "reject_df = train_df [train_df ['IsAcceptedAnswer'] == 0]\n",
    "\n",
    "D_accept = find_correlations_in_topics(accept_df)\n",
    "D_reject = find_correlations_in_topics(reject_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2 5\n",
      "1\n",
      "0 5\n",
      "2\n",
      "2 5\n",
      "3\n",
      "0 5\n",
      "4\n",
      "2 5\n",
      "5\n",
      "2 5\n",
      "6\n",
      "2 5\n",
      "7\n",
      "2 5\n",
      "8\n",
      "2 5\n",
      "9\n",
      "2 5\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "ans_topics = ['topic_0_ans', 'topic_1_ans', 'topic_2_ans', 'topic_3_ans','topic_4_ans', 'topic_5_ans',\n",
    "                  'topic_6_ans', 'topic_7_ans', 'topic_8_ans', 'topic_9_ans']\n",
    "qus_topics = ['topic_0_qus', 'topic_1_qus','topic_2_qus', 'topic_3_qus', 'topic_4_qus', 'topic_5_qus',\n",
    "                  'topic_6_qus', 'topic_7_qus', 'topic_8_qus', 'topic_9_qus']\n",
    "\n",
    "for i, row in train_df.iterrows():\n",
    "    ans_index = np.argmax(list(row[ans_topics]))\n",
    "    qus_index = np.argmax(list(row[qus_topics]))\n",
    "    print ans_index, qus_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some basic feature analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this section we will analyse some of the feature statistics after creating them all\n",
    "train_df = pd.read_csv(project_dir + '/data/clean_data/train_with_tag_clusters_and_user_scores.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
